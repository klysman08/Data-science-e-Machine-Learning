{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier comparison\n",
    "\n",
    "Classificadores a serem testados: $KNN$ (k: 9), $SVM$ (kernel: linear), $SVM$ (kernel: RBF), $Decision Tree$ (profundidade máxima: 10, critério: entropia), $Random Forest$ (profundidade máxima: 10, número de estimadores: 100) e $AdaBoost$.\n",
    "\n",
    "Métricas a serem computadas: accuracy, precision, recall, F1, AUC da ROC.\n",
    "\n",
    "Links úteis:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/classes.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "h = .02  # Step size in the mesh for plotting.\n",
    "\n",
    "# Classifier names.\n",
    "names = [\"Decision Tree 5\"]\n",
    "\n",
    "# Presetting classifiers.\n",
    "classifiers = [\n",
    "    DecisionTreeClassifier(max_depth=5)\n",
    "]\n",
    "\n",
    "# Presetting datasets.\n",
    "iris_indices = np.where(load_iris()['target'] < 2)[0]\n",
    "dataset_names = ['moons', 'circles', 'iris']\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            (load_iris()['data'][iris_indices, 0:2], load_iris()['target'][iris_indices])\n",
    "            ]\n",
    "\n",
    "# Presetting matplotlib figure.\n",
    "figure = plt.figure(figsize=(27, 27))\n",
    "marker_size = 85\n",
    "text_size = 25\n",
    "i = 1\n",
    "\n",
    "# Iterate over datasets.\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    \n",
    "    ds_name = dataset_names[ds_cnt]\n",
    "    \n",
    "    # Split into training and test part.\n",
    "    X, y = ds # X -> features, y -> labels.\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42) # Splitting.\n",
    "\n",
    "    # Printing dataset shapes.\n",
    "    print('')\n",
    "    print('####################################')\n",
    "    print('####################################')\n",
    "    print('Dataset', ds_name)\n",
    "    print('X_train', X_train.shape)\n",
    "    print('X_test', X_test.shape)\n",
    "    print('y_train', y_train.shape)\n",
    "    print('y_test', y_test.shape)\n",
    "    \n",
    "    # Finding boundaries.\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Just plot the dataset first.\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    \n",
    "    # Plot the training points;\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], marker_size, c=y_train, cmap=cm_bright, edgecolors='k', marker='*')\n",
    "    # and testing points.\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], marker_size, c=y_test, cmap=cm_bright, alpha=0.6, edgecolors='k', marker='o')\n",
    "    \n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # Iterate over classifiers.\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        \n",
    "        print('------------------------------------')\n",
    "        print('    ', 'Classifier', name)\n",
    "        \n",
    "        # Adding subplot.\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        \n",
    "        # Fitting classifier to train data.\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Obtaining class prediction for training data.\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "        \n",
    "        # Obtaining class prediction for unseen data.\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "        \n",
    "        # Computing error metrics in the training data.\n",
    "        acc_train = metrics.accuracy_score(y_train, y_pred_train)\n",
    "        \n",
    "        # Computing error metrics in the unseen data.\n",
    "        acc_test = metrics.accuracy_score(y_test, y_pred_test)\n",
    "        \n",
    "        # Printing error metrics.\n",
    "        print('        ', 'Accuracy Train/Test', acc_train, acc_test)\n",
    "\n",
    "        # Plot the decision boundary.\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot.\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot also the training points;\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], marker_size, c=y_train, cmap=cm_bright, edgecolors='k', marker='*')\n",
    "        # and testing points.\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], marker_size, c=y_test, cmap=cm_bright, edgecolors='k', marker='o', alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        \n",
    "        # Printing error metrics.\n",
    "        ax.text(xx.max() - .3, yy.min() + .3,  ('acc. %.2f / %.2f' % (acc_train, acc_test)).lstrip('0'), size=text_size, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
