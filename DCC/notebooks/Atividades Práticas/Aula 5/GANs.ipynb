{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "BQIJJ1cOMXF_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# Installing pillow v4.0.\n",
        "from PIL import Image\n",
        "!pip install Pillow==4.0.0\n",
        "!pip install image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NHt6G-mzWRS6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dataloader.py\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def dataloader(dataset, input_size, batch_size, split='train'):\n",
        "    transform = transforms.Compose([transforms.Resize((input_size, input_size)), transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "    if dataset == 'mnist':\n",
        "        data_loader = DataLoader(\n",
        "            datasets.MNIST('data/mnist', train=True, download=True, transform=transform),\n",
        "            batch_size=batch_size, shuffle=True)\n",
        "    elif dataset == 'fashion-mnist':\n",
        "        data_loader = DataLoader(\n",
        "            datasets.FashionMNIST('data/fashion-mnist', train=True, download=True, transform=transform),\n",
        "            batch_size=batch_size, shuffle=True)\n",
        "    elif dataset == 'cifar10':\n",
        "        data_loader = DataLoader(\n",
        "            datasets.CIFAR10('data/cifar10', train=True, download=True, transform=transform),\n",
        "            batch_size=batch_size, shuffle=True)\n",
        "    elif dataset == 'svhn':\n",
        "        data_loader = DataLoader(\n",
        "            datasets.SVHN('data/svhn', split=split, download=True, transform=transform),\n",
        "            batch_size=batch_size, shuffle=True)\n",
        "    elif dataset == 'stl10':\n",
        "        data_loader = DataLoader(\n",
        "            datasets.STL10('data/stl10', split=split, download=True, transform=transform),\n",
        "            batch_size=batch_size, shuffle=True)\n",
        "    elif dataset == 'lsun-bed':\n",
        "        data_loader = DataLoader(\n",
        "            datasets.LSUN('data/lsun', classes=['bedroom_train'], transform=transform),\n",
        "            batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return data_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O46IZfPWWKRx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# utils.py\n",
        "\n",
        "import os, gzip, torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def load_mnist(dataset):\n",
        "    data_dir = os.path.join(\"./data\", dataset)\n",
        "\n",
        "    def extract_data(filename, num_data, head_size, data_size):\n",
        "        with gzip.open(filename) as bytestream:\n",
        "            bytestream.read(head_size)\n",
        "            buf = bytestream.read(data_size * num_data)\n",
        "            data = np.frombuffer(buf, dtype=np.uint8).astype(np.float)\n",
        "        return data\n",
        "\n",
        "    data = extract_data(data_dir + '/train-images-idx3-ubyte.gz', 60000, 16, 28 * 28)\n",
        "    trX = data.reshape((60000, 28, 28, 1))\n",
        "\n",
        "    data = extract_data(data_dir + '/train-labels-idx1-ubyte.gz', 60000, 8, 1)\n",
        "    trY = data.reshape((60000))\n",
        "\n",
        "    data = extract_data(data_dir + '/t10k-images-idx3-ubyte.gz', 10000, 16, 28 * 28)\n",
        "    teX = data.reshape((10000, 28, 28, 1))\n",
        "\n",
        "    data = extract_data(data_dir + '/t10k-labels-idx1-ubyte.gz', 10000, 8, 1)\n",
        "    teY = data.reshape((10000))\n",
        "\n",
        "    trY = np.asarray(trY).astype(np.int)\n",
        "    teY = np.asarray(teY)\n",
        "\n",
        "    X = np.concatenate((trX, teX), axis=0)\n",
        "    y = np.concatenate((trY, teY), axis=0).astype(np.int)\n",
        "\n",
        "    seed = 547\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(X)\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(y)\n",
        "\n",
        "    y_vec = np.zeros((len(y), 10), dtype=np.float)\n",
        "    for i, label in enumerate(y):\n",
        "        y_vec[i, y[i]] = 1\n",
        "\n",
        "    X = X.transpose(0, 3, 1, 2) / 255.\n",
        "    # y_vec = y_vec.transpose(0, 3, 1, 2)\n",
        "\n",
        "    X = torch.from_numpy(X).type(torch.FloatTensor)\n",
        "    y_vec = torch.from_numpy(y_vec).type(torch.FloatTensor)\n",
        "    return X, y_vec\n",
        "\n",
        "def load_celebA(dir, transform, batch_size, shuffle):\n",
        "    # transform = transforms.Compose([\n",
        "    #     transforms.CenterCrop(160),\n",
        "    #     transform.Scale(64)\n",
        "    #     transforms.ToTensor(),\n",
        "    #     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "    # ])\n",
        "\n",
        "    # data_dir = 'data/celebA'  # this path depends on your computer\n",
        "    dset = datasets.ImageFolder(dir, transform)\n",
        "    data_loader = torch.utils.data.DataLoader(dset, batch_size, shuffle)\n",
        "\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "def print_network(net):\n",
        "    num_params = 0\n",
        "    for param in net.parameters():\n",
        "        num_params += param.numel()\n",
        "    print(net)\n",
        "    print('Total number of parameters: %d' % num_params)\n",
        "\n",
        "def save_images(images, size, image_path):\n",
        "    return imsave(images, size, image_path)\n",
        "\n",
        "def imsave(images, size, path):\n",
        "    image = np.squeeze(merge(images, size))\n",
        "    return scipy.misc.imsave(path, image)\n",
        "\n",
        "def merge(images, size):\n",
        "    h, w = images.shape[1], images.shape[2]\n",
        "    if (images.shape[3] in (3,4)):\n",
        "        c = images.shape[3]\n",
        "        img = np.zeros((h * size[0], w * size[1], c))\n",
        "        for idx, image in enumerate(images):\n",
        "            i = idx % size[1]\n",
        "            j = idx // size[1]\n",
        "            img[j * h:j * h + h, i * w:i * w + w, :] = image\n",
        "        return img\n",
        "    elif images.shape[3]==1:\n",
        "        img = np.zeros((h * size[0], w * size[1]))\n",
        "        for idx, image in enumerate(images):\n",
        "            i = idx % size[1]\n",
        "            j = idx // size[1]\n",
        "            img[j * h:j * h + h, i * w:i * w + w] = image[:,:,0]\n",
        "        return img\n",
        "    else:\n",
        "        raise ValueError('in merge(images,size) images parameter ''must have dimensions: HxW or HxWx3 or HxWx4')\n",
        "\n",
        "def generate_animation(path, num):\n",
        "    images = []\n",
        "    for e in range(num):\n",
        "        img_name = path + '_epoch%03d' % (e+1) + '.png'\n",
        "        images.append(imageio.imread(img_name))\n",
        "    imageio.mimsave(path + '_generate_animation.gif', images, fps=5)\n",
        "\n",
        "def loss_plot(hist, path = 'Train_hist.png', model_name = ''):\n",
        "    x = range(len(hist['D_loss']))\n",
        "\n",
        "    y1 = hist['D_loss']\n",
        "    y2 = hist['G_loss']\n",
        "\n",
        "    plt.plot(x, y1, label='D_loss')\n",
        "    plt.plot(x, y2, label='G_loss')\n",
        "\n",
        "    plt.xlabel('Iter')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.legend(loc=4)\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    path = os.path.join(path, model_name + '_loss.png')\n",
        "\n",
        "    plt.savefig(path)\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "def initialize_weights(net):\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            m.weight.data.normal_(0, 0.02)\n",
        "            m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.ConvTranspose2d):\n",
        "            m.weight.data.normal_(0, 0.02)\n",
        "            m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            m.weight.data.normal_(0, 0.02)\n",
        "            m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ei7m1nBiVaA1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GAN.py\n",
        "\n",
        "import torch, time, os, pickle\n",
        "# import utils, torch, time, os, pickle\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# from dataloader import dataloader\n",
        "\n",
        "class generator(nn.Module):\n",
        "    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
        "    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n",
        "    def __init__(self, input_dim=100, output_dim=1, input_size=32):\n",
        "        super(generator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # TO DO: Arquitetura da rede Generativa.\n",
        "        # Links úteis: https://pytorch.org/docs/stable/nn.html\n",
        "        self.fc = nn.Sequential(\n",
        "            \n",
        "        )\n",
        "        self.deconv = nn.Sequential(\n",
        "            \n",
        "        )\n",
        "        initialize_weights(self)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # TO DO: Forward da rede Generativa.\n",
        "        # Links úteis: https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
        "    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n",
        "    def __init__(self, input_dim=1, output_dim=1, input_size=32):\n",
        "        super(discriminator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # TO DO: Arquitetura da rede Discriminativa.\n",
        "        # Links úteis: https://pytorch.org/docs/stable/nn.html\n",
        "        self.conv = nn.Sequential(\n",
        "            \n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            \n",
        "        )\n",
        "        initialize_weights(self)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # TO DO: Forward da rede Discriminativa.\n",
        "        # Links úteis: https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view\n",
        "\n",
        "class GAN(object):\n",
        "    def __init__(self, args):\n",
        "        # parameters\n",
        "        self.epoch = args.epoch\n",
        "        self.sample_num = 100\n",
        "        self.batch_size = args.batch_size\n",
        "        self.save_dir = args.save_dir\n",
        "        self.result_dir = args.result_dir\n",
        "        self.dataset = args.dataset\n",
        "        self.log_dir = args.log_dir\n",
        "        self.gpu_mode = args.gpu_mode\n",
        "        self.model_name = args.gan_type\n",
        "        self.input_size = args.input_size\n",
        "        self.z_dim = 62\n",
        "\n",
        "        # load dataset\n",
        "        self.data_loader = dataloader(self.dataset, self.input_size, self.batch_size)\n",
        "        data = self.data_loader.__iter__().__next__()[0]\n",
        "\n",
        "        # networks init\n",
        "        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n",
        "        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n",
        "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n",
        "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n",
        "\n",
        "        if self.gpu_mode:\n",
        "            self.G.cuda()\n",
        "            self.D.cuda()\n",
        "            self.BCE_loss = nn.BCELoss().cuda()\n",
        "        else:\n",
        "            self.BCE_loss = nn.BCELoss()\n",
        "\n",
        "        print('---------- Networks architecture -------------')\n",
        "        print_network(self.G)\n",
        "        print_network(self.D)\n",
        "        print('-----------------------------------------------')\n",
        "\n",
        "\n",
        "        # fixed noise\n",
        "        self.sample_z_ = torch.rand((self.batch_size, self.z_dim))\n",
        "        if self.gpu_mode:\n",
        "            self.sample_z_ = self.sample_z_.cuda()\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.train_hist = {}\n",
        "        self.train_hist['D_loss'] = []\n",
        "        self.train_hist['G_loss'] = []\n",
        "        self.train_hist['per_epoch_time'] = []\n",
        "        self.train_hist['total_time'] = []\n",
        "\n",
        "        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n",
        "        if self.gpu_mode:\n",
        "            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n",
        "\n",
        "        self.D.train()\n",
        "        print('training start!!')\n",
        "        start_time = time.time()\n",
        "        for epoch in range(self.epoch):\n",
        "            self.G.train()\n",
        "            epoch_start_time = time.time()\n",
        "            for iter, (x_, _) in enumerate(self.data_loader):\n",
        "                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n",
        "                    break\n",
        "\n",
        "                z_ = torch.rand((self.batch_size, self.z_dim))\n",
        "                if self.gpu_mode:\n",
        "                    x_, z_ = x_.cuda(), z_.cuda()\n",
        "\n",
        "                # update D network\n",
        "                self.D_optimizer.zero_grad()\n",
        "\n",
        "                D_real = self.D(x_)\n",
        "                D_real_loss = self.BCE_loss(D_real, self.y_real_)\n",
        "\n",
        "                G_ = self.G(z_)\n",
        "                D_fake = self.D(G_)\n",
        "                D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n",
        "\n",
        "                D_loss = D_real_loss + D_fake_loss\n",
        "                self.train_hist['D_loss'].append(D_loss.item())\n",
        "\n",
        "                D_loss.backward()\n",
        "                self.D_optimizer.step()\n",
        "\n",
        "                # update G network\n",
        "                self.G_optimizer.zero_grad()\n",
        "\n",
        "                G_ = self.G(z_)\n",
        "                D_fake = self.D(G_)\n",
        "                G_loss = self.BCE_loss(D_fake, self.y_real_)\n",
        "                self.train_hist['G_loss'].append(G_loss.item())\n",
        "\n",
        "                G_loss.backward()\n",
        "                self.G_optimizer.step()\n",
        "\n",
        "                print_interval = 100\n",
        "                    \n",
        "                if ((iter + 1) % print_interval) == 0:\n",
        "                    print(\"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f\" %\n",
        "                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n",
        "                    \n",
        "                    fig, ax = plt.subplots(1, 4, figsize=(8, 2))\n",
        "\n",
        "                    for i in range(4):\n",
        "                        ax[i].imshow(G_[i].squeeze().cpu().detach().numpy())\n",
        "                        ax[i].set_xticks([])\n",
        "                        ax[i].set_yticks([])\n",
        "\n",
        "                    plt.show()\n",
        "\n",
        "            self.train_hist['per_epoch_time'].append(time.time() - epoch_start_time)\n",
        "            with torch.no_grad():\n",
        "                self.visualize_results((epoch+1))\n",
        "\n",
        "        self.train_hist['total_time'].append(time.time() - start_time)\n",
        "        print(\"Avg one epoch time: %.2f, total %d epochs time: %.2f\" % (np.mean(self.train_hist['per_epoch_time']),\n",
        "              self.epoch, self.train_hist['total_time'][0]))\n",
        "        print(\"Training finish!... save training results\")\n",
        "\n",
        "        self.save()\n",
        "#         utils.generate_animation(self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name,\n",
        "#                                  self.epoch)\n",
        "#         utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n",
        "        generate_animation(self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name,\n",
        "                                 self.epoch)\n",
        "        loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n",
        "\n",
        "    def visualize_results(self, epoch, fix=True):\n",
        "        self.G.eval()\n",
        "\n",
        "        if not os.path.exists(self.result_dir + '/' + self.dataset + '/' + self.model_name):\n",
        "            os.makedirs(self.result_dir + '/' + self.dataset + '/' + self.model_name)\n",
        "\n",
        "        tot_num_samples = min(self.sample_num, self.batch_size)\n",
        "        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n",
        "\n",
        "        if fix:\n",
        "            \"\"\" fixed noise \"\"\"\n",
        "            samples = self.G(self.sample_z_)\n",
        "        else:\n",
        "            \"\"\" random noise \"\"\"\n",
        "            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n",
        "            if self.gpu_mode:\n",
        "                sample_z_ = sample_z_.cuda()\n",
        "\n",
        "            samples = self.G(sample_z_)\n",
        "\n",
        "        if self.gpu_mode:\n",
        "            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
        "        else:\n",
        "            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n",
        "\n",
        "        samples = (samples + 1) / 2\n",
        "#         utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n",
        "#                           self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name + '_epoch%03d' % epoch + '.png')\n",
        "        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n",
        "                          self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name + '_epoch%03d' % epoch + '.png')\n",
        "\n",
        "    def save(self):\n",
        "        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n",
        "\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "\n",
        "        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + '_G.pkl'))\n",
        "        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + '_D.pkl'))\n",
        "\n",
        "        with open(os.path.join(save_dir, self.model_name + '_history.pkl'), 'wb') as f:\n",
        "            pickle.dump(self.train_hist, f)\n",
        "\n",
        "    def load(self):\n",
        "        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n",
        "\n",
        "        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_G.pkl')))\n",
        "        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_D.pkl')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HIzz507HNqKh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import argparse, os, torch\n",
        "\n",
        "################################################################################\n",
        "# Adapted from: https://github.com/znxlwm/pytorch-generative-model-collections #\n",
        "################################################################################\n",
        "\n",
        "\"\"\"parsing and configuration\"\"\"\n",
        "def parse_args():\n",
        "    desc = \"Pytorch implementation of GAN collections\"\n",
        "    #parser = argparse.ArgumentParser(description=desc)\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='Searching longest common substring. '\n",
        "                    'Uses Ukkonen\\'s suffix tree algorithm and generalized suffix tree. '\n",
        "                    'Written by Ilya Stepanov (c) 2013')\n",
        "\n",
        "    parser.add_argument('--gan_type', type=str, default='GAN', choices=['GAN', 'CGAN', 'infoGAN', 'ACGAN', 'EBGAN', 'BEGAN', 'WGAN', 'WGAN_GP', 'DRAGAN', 'LSGAN'], help='The type of GAN')\n",
        "    parser.add_argument('--dataset', type=str, default='mnist', choices=['mnist', 'fashion-mnist', 'cifar10', 'cifar100', 'svhn', 'stl10', 'lsun-bed'], help='The name of dataset')\n",
        "    parser.add_argument('--split', type=str, default='', help='The split flag for svhn and stl10')\n",
        "    parser.add_argument('--epoch', type=int, default=50, help='The number of epochs to run')\n",
        "    parser.add_argument('--batch_size', type=int, default=64, help='The size of batch')\n",
        "    parser.add_argument('--input_size', type=int, default=28, help='The size of input image')\n",
        "    parser.add_argument('--save_dir', type=str, default='models', help='Directory name to save the model')\n",
        "    parser.add_argument('--result_dir', type=str, default='results', help='Directory name to save the generated images')\n",
        "    parser.add_argument('--log_dir', type=str, default='logs', help='Directory name to save training logs')\n",
        "    parser.add_argument('--lrG', type=float, default=0.0002)\n",
        "    parser.add_argument('--lrD', type=float, default=0.0002)\n",
        "    parser.add_argument('--beta1', type=float, default=0.5)\n",
        "    parser.add_argument('--beta2', type=float, default=0.999)\n",
        "    parser.add_argument('--gpu_mode', type=bool, default=True)\n",
        "    parser.add_argument('--benchmark_mode', type=bool, default=True)\n",
        "\n",
        "    return check_args(parser.parse_args(\"--gan_type GAN --dataset mnist\".split()))\n",
        "    return check_args(parser.parse_args())\n",
        "\n",
        "\"\"\"checking arguments\"\"\"\n",
        "def check_args(args):\n",
        "    # --save_dir\n",
        "    if not os.path.exists(args.save_dir):\n",
        "        os.makedirs(args.save_dir)\n",
        "\n",
        "    # --result_dir\n",
        "    if not os.path.exists(args.result_dir):\n",
        "        os.makedirs(args.result_dir)\n",
        "\n",
        "    # --result_dir\n",
        "    if not os.path.exists(args.log_dir):\n",
        "        os.makedirs(args.log_dir)\n",
        "\n",
        "    # --epoch\n",
        "    try:\n",
        "        assert args.epoch >= 1\n",
        "    except:\n",
        "        print('number of epochs must be larger than or equal to one')\n",
        "\n",
        "    # --batch_size\n",
        "    try:\n",
        "        assert args.batch_size >= 1\n",
        "    except:\n",
        "        print('batch size must be larger than or equal to one')\n",
        "\n",
        "    return args\n",
        "\n",
        "\"\"\"main\"\"\"\n",
        "def main():\n",
        "    # parse arguments\n",
        "    args = parse_args()\n",
        "    if args is None:\n",
        "        exit()\n",
        "\n",
        "    if args.benchmark_mode:\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    gan = GAN(args)\n",
        "    \n",
        "    gan.train()\n",
        "    print(\" [*] Training finished!\")\n",
        "\n",
        "    # visualize learned generator\n",
        "    gan.visualize_results(args.epoch)\n",
        "    print(\" [*] Testing finished!\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WINf_6phbP3N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls results/mnist/GAN/\n",
        "\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "img10 = io.imread('results/mnist/GAN/GAN_epoch020.png').astype(np.float)\n",
        "img20 = io.imread('results/mnist/GAN/GAN_epoch050.png').astype(np.float)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize = (16, 8), sharex = True, sharey = True)\n",
        "ax[0].imshow(img10, interpolation='nearest', cmap=plt.cm.gray)\n",
        "ax[1].imshow(img20, interpolation='nearest', cmap=plt.cm.gray)\n",
        "\n",
        "ax[0].set_xticks([])\n",
        "ax[0].set_yticks([])\n",
        "\n",
        "ax[1].set_xticks([])\n",
        "ax[1].set_yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}