{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Convolutional_AE_Gabarito.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"Bu6ImUZLGAcM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":433},"outputId":"bfb2232a-ac68-48a6-907c-c3ef63bd5418","executionInfo":{"status":"ok","timestamp":1535167421205,"user_tz":180,"elapsed":58130,"user":{"displayName":"Hugo Neves","photoUrl":"//lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s50-c-k-no/photo.jpg","userId":"115244738658251423663"}}},"cell_type":"code","source":["from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n","import torch\n","print(torch.__version__)\n","print(torch.cuda.is_available())\n","\n","# Installing pillow v4.0.\n","from PIL import Image\n","!pip install Pillow==4.0.0\n","!pip install image"],"execution_count":1,"outputs":[{"output_type":"stream","text":["tcmalloc: large alloc 1073750016 bytes == 0x5c6ac000 @  0x7f986fdb61c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\r\n","0.4.0\n","True\n","Collecting Pillow==4.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.6MB)\n","\u001b[K    100% |████████████████████████████████| 5.6MB 3.9MB/s \n","\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.45.1)\n","\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n","Installing collected packages: Pillow\n","  Found existing installation: Pillow 5.2.0\n","    Uninstalling Pillow-5.2.0:\n","      Successfully uninstalled Pillow-5.2.0\n","Successfully installed Pillow-4.0.0\n","Collecting image\n","  Downloading https://files.pythonhosted.org/packages/a7/5b/c0358fe83daab29070e38a945809585f1fd6353e65b687f602688f32c3c2/image-1.5.24-py2.py3-none-any.whl\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.0.0)\n","Collecting django (from image)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/1a/e0ac7886c7123a03814178d7517dc822af0fe51a72e1a6bff26153103322/Django-2.1-py3-none-any.whl (7.3MB)\n","\u001b[K    100% |████████████████████████████████| 7.3MB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.45.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.5)\n","Installing collected packages: django, image\n","Successfully installed django-2.1 image-1.5.24\n"],"name":"stdout"}]},{"metadata":{"id":"fcU-gYDgGwfQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68334,"output_embedded_package_id":"13FVPCLbrStpNxoVu58Gkz-VLG341zgS8"},"outputId":"b1b16a8c-a512-4e5c-ff7a-a08b995618b2","executionInfo":{"status":"ok","timestamp":1535169480118,"user_tz":180,"elapsed":1857101,"user":{"displayName":"Hugo Neves","photoUrl":"//lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s50-c-k-no/photo.jpg","userId":"115244738658251423663"}}},"cell_type":"code","source":["import torch\n","import torchvision\n","from torch import nn\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from torchvision.utils import save_image\n","from torchvision.datasets import MNIST\n","import os\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","###########################################################################################\n","# Adapted from: https://github.com/L1aoXingyu/pytorch-beginner/tree/master/08-AutoEncoder #\n","###########################################################################################\n","\n","if not os.path.exists('./dc_img'):\n","    os.mkdir('./dc_img')\n","\n","def to_img(x):\n","    x = 0.5 * (x + 1)\n","    x = x.clamp(0, 1)\n","    x = x.view(x.size(0), 1, 28, 28)\n","    return x\n","\n","# Parameters.\n","num_epochs = 100\n","batch_size = 64\n","learning_rate = 1e-3\n","\n","# Defining normalization routine to images.\n","img_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Instancing Dataloader and Dataset.\n","dataset = MNIST('./data', transform=img_transform, download=True)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# Defining model.\n","class autoencoder(nn.Module):\n","    def __init__(self):\n","        super(autoencoder, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(1, 8, 3, stride=3, padding=1),  # b, 16, 10, 10\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n","            nn.Conv2d(8, 4, 3, stride=2, padding=1),  # b, 8, 3, 3\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(4, 8, 3, stride=2),  # b, 16, 5, 5\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(8, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        \n","        z = self.encoder(x)\n","        out = self.decoder(z)\n","        return out\n","\n","\n","# Instancing Model\n","model = autoencoder().cuda()\n","\n","# Defining Criterion\n","criterion = nn.MSELoss()\n","\n","# Defining Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n","\n","# Iterating over epochs.\n","for epoch in range(num_epochs):\n","\n","    # Iterating over batches.\n","    for it, data in enumerate(dataloader):\n","\n","        # Reading data and casting to GPU.\n","        img, _ = data\n","        img = Variable(img).cuda()\n","        \n","        # Forward.\n","        output = model(img)\n","        loss = criterion(output, img)\n","        \n","        # Backward.\n","        optimizer.zero_grad()\n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        # Plotting first batch of each epoch.\n","        if it == 0:\n","            \n","            fig, ax = plt.subplots(8, 8, figsize=(12, 12))\n","            for i in range(8):\n","                for j in range(8):\n","                    ax[i, j].imshow(output.cpu()[i + 4 * j].detach().numpy()[0])\n","                    ax[i, j].set_yticks([])\n","                    ax[i, j].set_xticks([])\n","            plt.show()\n","            \n","    # Printing log.\n","    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.data[0]))\n","\n","# Saving model to disk.\n","torch.save(model.state_dict(), './conv_autoencoder.pth')"],"execution_count":3}]}