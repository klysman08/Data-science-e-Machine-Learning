{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VAE.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"mKKB3t5n7Lmf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":314},"outputId":"bbd0ca9a-83cb-4cc2-dbc9-25ba7c397e21","executionInfo":{"status":"ok","timestamp":1535169552521,"user_tz":180,"elapsed":9046,"user":{"displayName":"Hugo Neves","photoUrl":"//lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s50-c-k-no/photo.jpg","userId":"115244738658251423663"}}},"cell_type":"code","source":["from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n","import torch\n","print(torch.__version__)\n","print(torch.cuda.is_available())\n","\n","# Installing pillow v4.0.\n","from PIL import Image\n","!pip install Pillow==4.0.0\n","!pip install image"],"execution_count":1,"outputs":[{"output_type":"stream","text":["0.4.0\n","True\n","Collecting Pillow==4.0.0\n","  Using cached https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.45.1)\n","\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n","Installing collected packages: Pillow\n","  Found existing installation: Pillow 5.2.0\n","    Uninstalling Pillow-5.2.0:\n","      Successfully uninstalled Pillow-5.2.0\n","Successfully installed Pillow-4.0.0\n","Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.24)\n","Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.0.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.5)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.45.1)\n"],"name":"stdout"}]},{"metadata":{"id":"Wri08OqE9V08","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir results"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4TaHmOcs7Qrg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":39369,"output_embedded_package_id":"1bbk8C8dVLwdQDnOTqM0dXl4Ak-hrTMxE"},"outputId":"83fe9015-5990-4ce4-b55e-f16ba1aa157a","executionInfo":{"status":"ok","timestamp":1535170331391,"user_tz":180,"elapsed":739521,"user":{"displayName":"Hugo Neves","photoUrl":"//lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s50-c-k-no/photo.jpg","userId":"115244738658251423663"}}},"cell_type":"code","source":["from __future__ import print_function\n","import argparse\n","import torch\n","import torch.utils.data\n","from torch import nn, optim\n","from torch.nn import functional as F\n","from torchvision import datasets, transforms\n","from torchvision.utils import save_image\n","\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","#####################################################################\n","# Adapted from: https://github.com/pytorch/examples/tree/master/vae #\n","#####################################################################\n","\n","# parser = argparse.ArgumentParser(description='VAE MNIST Example')\n","# parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n","#                     help='input batch size for training (default: 128)')\n","# parser.add_argument('--epochs', type=int, default=10, metavar='N',\n","#                     help='number of epochs to train (default: 10)')\n","# parser.add_argument('--no-cuda', action='store_true', default=False,\n","#                     help='enables CUDA training')\n","# parser.add_argument('--seed', type=int, default=1, metavar='S',\n","#                     help='random seed (default: 1)')\n","# parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n","#                     help='how many batches to wait before logging training status')\n","# args = parser.parse_args('--batch-size 128 --epochs 50')\n","# args.cuda = not args.no_cuda and torch.cuda.is_available()\n","\n","batch_size = 128\n","epochs = 50\n","log_interval = 100\n","\n","cuda = True\n","\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                   transform=transforms.ToTensor()),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","\n","\n","class VAE(nn.Module):\n","    def __init__(self):\n","        super(VAE, self).__init__()\n","\n","        self.fc1 = nn.Linear(784, 400)\n","        self.fc21 = nn.Linear(400, 20)\n","        self.fc22 = nn.Linear(400, 20)\n","        self.fc3 = nn.Linear(20, 400)\n","        self.fc4 = nn.Linear(400, 784)\n","\n","    def encode(self, x):\n","        h1 = F.relu(self.fc1(x))\n","        return self.fc21(h1), self.fc22(h1)\n","\n","    def reparameterize(self, mu, logvar):\n","        if self.training:\n","            std = torch.exp(0.5*logvar)\n","            eps = torch.randn_like(std)\n","            return eps.mul(std).add_(mu)\n","        else:\n","            return mu\n","\n","    def decode(self, z):\n","        h3 = F.relu(self.fc3(z))\n","        return F.sigmoid(self.fc4(h3))\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x.view(-1, 784))\n","#         print('mu, std', mu.size(), logvar.size())\n","        z = self.reparameterize(mu, logvar)\n","#         print('z', z.size())\n","        return self.decode(z), mu, logvar\n","\n","\n","model = VAE().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","\n","# Reconstruction + KL divergence losses summed over all elements and batch\n","def loss_function(recon_x, x, mu, logvar):\n","    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), size_average=False)\n","\n","    # see Appendix B from VAE paper:\n","    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n","    # https://arxiv.org/abs/1312.6114\n","    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n","    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","\n","    return BCE + KLD\n","\n","\n","def train(epoch):\n","    model.train()\n","    train_loss = 0\n","    for batch_idx, (data, _) in enumerate(train_loader):\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        recon_batch, mu, logvar = model(data)\n","        loss = loss_function(recon_batch, data, mu, logvar)\n","        loss.backward()\n","        train_loss += loss.item()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader),\n","                loss.item() / len(data)))\n","\n","    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n","\n","\n","def test(epoch):\n","    model.eval()\n","    test_loss = 0\n","    with torch.no_grad():\n","        for i, (data, _) in enumerate(test_loader):\n","            data = data.to(device)\n","            recon_batch, mu, logvar = model(data)\n","            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n","            if i == 0:\n","                n = min(data.size(0), 8)\n","                comparison = torch.cat([data[:n], recon_batch.view(batch_size, 1, 28, 28)[:n]])\n","                save_image(comparison.cpu(), 'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n","\n","    test_loss /= len(test_loader.dataset)\n","    print('====> Test set loss: {:.4f}'.format(test_loss))\n","\n","\n","for epoch in range(1, epochs + 1):\n","    train(epoch)\n","    test(epoch)\n","    with torch.no_grad():\n","        sample = torch.randn(64, 20).to(device)\n","        sample = model.decode(sample).cpu().view(64, 1, 28, 28)\n","        save_image(sample, 'results/sample_' + str(epoch) + '.png')\n","        \n","        fig, ax = plt.subplots(8, 8, figsize=(12, 12))\n","        for i in range(8):\n","            for j in range(8):\n","                ax[i, j].imshow(sample[i + 4 * j].numpy()[0])\n","                ax[i, j].set_yticks([])\n","                ax[i, j].set_xticks([])\n","        plt.show()"],"execution_count":3}]}