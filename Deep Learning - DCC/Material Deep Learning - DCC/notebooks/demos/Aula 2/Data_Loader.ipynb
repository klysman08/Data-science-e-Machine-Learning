{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data_Loader.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"Tt1TUTUh_wlh","colab_type":"text"},"cell_type":"markdown","source":["# Data Loader\n","\n","Data structure for loading data in parallel to the model training procedure. $DataLoader$ and $Dataset$ objects load (in a multithreaded fashion), preprocess and concatenate tensors/ndarrays/list/dicts, sending them in batches to the training procedure."]},{"metadata":{"id":"chWXQmTj_wli","colab_type":"text"},"cell_type":"markdown","source":["## Defining the custom Dataset subclass"]},{"metadata":{"id":"PDsIziBI_wlj","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import numpy as np\n","import torch\n","\n","from torch.utils import data\n","from skimage import io\n","\n","# Constants.\n","num_classes = 10\n","root = '../../../data/mnist/'\n","\n","# Class that reads a sequence of image paths from a text file and creates a data.Dataset with them.\n","class CustomDataset(data.Dataset):\n","\n","    def __init__(self, fold, normalization = 'default'):\n","\n","        super(CustomDataset, self).__init__()\n","        \n","        # Initializing variables.\n","        self.fold = fold\n","        self.normalization = normalization\n","\n","        # Creating list of paths.\n","        self.imgs = self.make_dataset()\n","\n","        # Check for consistency in list.\n","        if len(self.imgs) == 0:\n","\n","            raise (RuntimeError('Found 0 images, please check the data set'))\n","\n","    def make_dataset(self):\n","\n","        # Initiating item list.\n","        items = []\n","\n","        # Joining input paths.\n","        img_path = os.path.join(root, self.fold)\n","\n","        # Reading paths from file.\n","        #data_list = [l.strip('\\n') for l in open(os.path.join(root, self.dataset, self.task + '_' + mode_str + '_f' + self.fold + '.txt')).readlines()]\n","\n","        # Reading paths from directory.\n","        data_list = [f for f in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, f))]\n","        \n","        # Creating list containing image and ground truth paths.\n","        for it in data_list:\n","            item = os.path.join(img_path, it)\n","            items.append(item)\n","\n","        # Returning list.\n","        return items\n","\n","    def __getitem__(self, index):\n","\n","        # Reading items from list.\n","        img_path = self.imgs[index]\n","\n","        # Reading images.\n","        img = io.imread(img_path)\n","        \n","        # Reading label from image file.\n","        lab = int(img_path[-5])\n","\n","        # Removing unwanted channels. For the case of RGB images.\n","        if len(img.shape) > 2:\n","            img = img[:, :, 0]\n","\n","        # Casting images to the appropriate dtypes.\n","        img = img.astype(np.float32)\n","\n","        # Normalization.\n","        if self.normalization == 'statistical':\n","\n","            img = (img - img.mean()) / img.std()\n","\n","        else:\n","\n","            mn = img.min()\n","            mx = img.max()\n","            img = ((img - mn) / (mx - mn))\n","\n","        # Adding channel dimension.\n","        img = np.expand_dims(img, axis=0)\n","\n","        # Turning to tensors.\n","        img = torch.from_numpy(img)\n","\n","        # Returning to iterator.\n","        return img, lab\n","\n","    def __len__(self):\n","\n","        return len(self.imgs)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"niTKEuEC_wlm","colab_type":"text"},"cell_type":"markdown","source":["## Iterating over dataset"]},{"metadata":{"scrolled":false,"id":"MGli3kQ-_wln","colab_type":"code","colab":{}},"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from matplotlib import pyplot as plt\n","\n","%matplotlib inline\n","\n","# Setting data loader.\n","batch_size = 1\n","num_workers = 4\n","\n","# train_set = ListDataset('train')\n","# train_loader = DataLoader(train_set, batch_size, num_workers=num_workers, shuffle=True)\n","test_set = CustomDataset('test')\n","test_loader = DataLoader(test_set, batch_size, num_workers=num_workers, shuffle=False)\n","\n","# Iterating over batches.\n","# for it, data in enumerate(train_loader):\n","for it, data in enumerate(test_loader):\n","\n","    # Obtaining images and labels for batch.\n","    inps, labs = data\n","\n","    print('#####################################')\n","    print('Iteration: ', it)\n","    print('Data Size: ', inps.size())\n","    print('Labels Size: ', labs.size())\n","    print('')\n","    \n","    plt.imshow(inps[0].squeeze().data.numpy())\n","    plt.xlabel('Label: ' + str(labs[0].numpy()))\n","    plt.show()\n","    \n","    # Ending for early for visualization.\n","    if it >= 10:\n","        break\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"vj_e9SSD_wlr","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}