{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_Procedure_MLP_Gabarito.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1Ryrv4mhgBXqllQNu5mWHH8En5O-WjCf7",
          "timestamp": 1532878867492
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Il7H73VGJ2No",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Procedure"
      ]
    },
    {
      "metadata": {
        "id": "DjbxoKABJ6K1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fea05c49-500e-42eb-e1b2-6b94ed243eff",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532880149882,
          "user_tz": 180,
          "elapsed": 5957,
          "user": {
            "displayName": "Hugo Neves",
            "photoUrl": "//lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s50-c-k-no/photo.jpg",
            "userId": "115244738658251423663"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "abQOyifrLFBE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "da23336d-734d-4685-9f86-750597ad17eb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532880168916,
          "user_tz": 180,
          "elapsed": 19008,
          "user": {
            "displayName": "Hugo Neves",
            "photoUrl": "//lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s50-c-k-no/photo.jpg",
            "userId": "115244738658251423663"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -r ./mnist\n",
        "\n",
        "!wget https://www.dropbox.com/s/5yre1ofqco5titj/mnist.zip?dl=0 -O mnist.zip\n",
        "!unzip -q mnist.zip\n",
        "\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-07-29 16:02:34--  https://www.dropbox.com/s/5yre1ofqco5titj/mnist.zip?dl=0\r\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/5yre1ofqco5titj/mnist.zip [following]\n",
            "--2018-07-29 16:02:35--  https://www.dropbox.com/s/raw/5yre1ofqco5titj/mnist.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc6ed5c57c7a251ec2f61eb6ee29.dl.dropboxusercontent.com/cd/0/inline/AMnvIVxk3xVuVA-faUjluTOdLHmgA7aiwk3TgL1BljZlTGuGpBR2a7UCiXn9CTtlRsC-RYdGw81K3lYNpYs6dfhV9acE3abZYlKQjKgLp2ivgbsWX2lRt7C6hHSCad3lcydF85CGDPxUeqJzst7CUGrnVRD4WO8pCfzuaMHuK0xO5a0eXoBaJCoKg1zqAY3pznZBtEcMLcPHA100UZNv3YoA/file [following]\n",
            "--2018-07-29 16:02:35--  https://uc6ed5c57c7a251ec2f61eb6ee29.dl.dropboxusercontent.com/cd/0/inline/AMnvIVxk3xVuVA-faUjluTOdLHmgA7aiwk3TgL1BljZlTGuGpBR2a7UCiXn9CTtlRsC-RYdGw81K3lYNpYs6dfhV9acE3abZYlKQjKgLp2ivgbsWX2lRt7C6hHSCad3lcydF85CGDPxUeqJzst7CUGrnVRD4WO8pCfzuaMHuK0xO5a0eXoBaJCoKg1zqAY3pznZBtEcMLcPHA100UZNv3YoA/file\n",
            "Resolving uc6ed5c57c7a251ec2f61eb6ee29.dl.dropboxusercontent.com (uc6ed5c57c7a251ec2f61eb6ee29.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc6ed5c57c7a251ec2f61eb6ee29.dl.dropboxusercontent.com (uc6ed5c57c7a251ec2f61eb6ee29.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AMkU0_qDXjp_r2GE-gH1C4ORtdh6GRu-29xvpDNKjR1Y5AbgS7gmcJsYC7CMeMwO70tTgziczB9EWp3LelwosgdpXIZ9q11bj0X5mq6zS9dCBghWNPZ9iLzwXWyvxyRSg76UXRmS4qIVltr-Ak77ZkJXDrTcIG3Nd-NpOnSienOVN6OcMNCwaslc1btcxIhHXo8Mq1D0We3CgWe_ttCHrpt9HcTA0zH7ifo16ZD0GUrJLVTBeTLsbWAvsLLic9EpXMyYEcsjrDLV9hNGGet7LzmrDLxjszAlIkLE2hEGdxIUFRjoMGy1oHDt9CXzDpU_sA01D8aPP-oL6qt5gAMPj3_pgq63OWLE7m5isD2PybjhrYQKnttQet5FOSNz1Znj0l6nCXkdKdmBgro1uvo1RDJhCT5Q8bU7MboJ3W1h84UKlDzy7I5XHjru8fBcK1CwkL5k5CseS1Jn5Lq0HzqyN552/file [following]\n",
            "--2018-07-29 16:02:36--  https://uc6ed5c57c7a251ec2f61eb6ee29.dl.dropboxusercontent.com/cd/0/inline2/AMkU0_qDXjp_r2GE-gH1C4ORtdh6GRu-29xvpDNKjR1Y5AbgS7gmcJsYC7CMeMwO70tTgziczB9EWp3LelwosgdpXIZ9q11bj0X5mq6zS9dCBghWNPZ9iLzwXWyvxyRSg76UXRmS4qIVltr-Ak77ZkJXDrTcIG3Nd-NpOnSienOVN6OcMNCwaslc1btcxIhHXo8Mq1D0We3CgWe_ttCHrpt9HcTA0zH7ifo16ZD0GUrJLVTBeTLsbWAvsLLic9EpXMyYEcsjrDLV9hNGGet7LzmrDLxjszAlIkLE2hEGdxIUFRjoMGy1oHDt9CXzDpU_sA01D8aPP-oL6qt5gAMPj3_pgq63OWLE7m5isD2PybjhrYQKnttQet5FOSNz1Znj0l6nCXkdKdmBgro1uvo1RDJhCT5Q8bU7MboJ3W1h84UKlDzy7I5XHjru8fBcK1CwkL5k5CseS1Jn5Lq0HzqyN552/file\n",
            "Reusing existing connection to uc6ed5c57c7a251ec2f61eb6ee29.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 70196075 (67M) [application/zip]\n",
            "Saving to: ‘mnist.zip’\n",
            "\n",
            "mnist.zip           100%[===================>]  66.94M  20.1MB/s    in 3.9s    \n",
            "\n",
            "2018-07-29 16:02:40 (17.1 MB/s) - ‘mnist.zip’ saved [70196075/70196075]\n",
            "\n",
            "datalab  mnist\tmnist.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5yNikfN0J2Np",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setting data loader\n",
        "\n",
        "Creating data loader for reading images from the training and test sets."
      ]
    },
    {
      "metadata": {
        "id": "YKPo231vJ2Nq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8e8e483f-e70e-46cc-caa0-9e08ae1a44ca",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532880171195,
          "user_tz": 180,
          "elapsed": 2240,
          "user": {
            "displayName": "Hugo Neves",
            "photoUrl": "//lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s50-c-k-no/photo.jpg",
            "userId": "115244738658251423663"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import PIL\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from skimage import io\n",
        "\n",
        "# Constants.\n",
        "num_classes = 10\n",
        "root = 'mnist/'\n",
        "\n",
        "# Class that reads a sequence of image paths from a text file and creates a data.Dataset with them.\n",
        "class CustomDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, fold, normalization = 'default'):\n",
        "\n",
        "        super(CustomDataset, self).__init__()\n",
        "        \n",
        "        # Initializing variables.\n",
        "        self.fold = fold\n",
        "        self.normalization = normalization\n",
        "\n",
        "        # Creating list of paths.\n",
        "        self.imgs = self.make_dataset()\n",
        "\n",
        "        # Check for consistency in list.\n",
        "        if len(self.imgs) == 0:\n",
        "\n",
        "            raise (RuntimeError('Found 0 images, please check the data set'))\n",
        "\n",
        "    def make_dataset(self):\n",
        "\n",
        "        # Initiating item list.\n",
        "        items = []\n",
        "\n",
        "        # Joining input paths.\n",
        "        img_path = os.path.join(root, self.fold)\n",
        "\n",
        "        # Reading paths from text file.\n",
        "        #data_list = [l.strip('\\n') for l in open(os.path.join(root, self.dataset, self.task + '_' + mode_str + '_f' + self.fold + '.txt')).readlines()]\n",
        "\n",
        "        # Reading paths from directory.\n",
        "        data_list = [f for f in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, f))]\n",
        "        \n",
        "        # Creating list containing image and ground truth paths.\n",
        "        for it in data_list:\n",
        "            item = os.path.join(img_path, it)\n",
        "            items.append(item)\n",
        "\n",
        "        # Returning list.\n",
        "        return items\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # Reading items from list.\n",
        "        img_path = self.imgs[index]\n",
        "        \n",
        "#         print(img_path)\n",
        "        \n",
        "        # Reading images.\n",
        "        img = io.imread(img_path)        \n",
        "        \n",
        "        # Reading label from image file.\n",
        "        lab = int(img_path[-5])\n",
        "        \n",
        "        # Removing unwanted channels. For the case of RGB images.\n",
        "        if len(img.shape) > 2:\n",
        "            img = img[:, :, 0] # Leaving only red (index = 0) channel from RGB.\n",
        "        \n",
        "        # Casting images to the appropriate dtypes.\n",
        "        img = img.astype(np.float32)\n",
        "        \n",
        "        # Normalization.\n",
        "        mn = img.min()\n",
        "        mx = img.max()\n",
        "        img = ((img - mn) / (mx - mn))\n",
        "        \n",
        "        # Adding channel dimension.\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        \n",
        "        # Turning to tensors.\n",
        "        img = torch.from_numpy(img)\n",
        "        \n",
        "        # Returning image and label to iterator.\n",
        "        return img, lab\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.imgs)\n",
        "\n",
        "# Setting data loader.\n",
        "batch_size = 100\n",
        "num_workers = 1 # Number of Threads on each data_loader.\n",
        "\n",
        "train_set = CustomDataset('train')\n",
        "train_loader = DataLoader(train_set, batch_size, num_workers=num_workers, shuffle=True)\n",
        "\n",
        "test_set = CustomDataset('test')\n",
        "test_loader = DataLoader(test_set, batch_size, num_workers=num_workers, shuffle=False)\n",
        "\n",
        "print('Size of training set: ' + str(len(train_set)) + ' samples')\n",
        "print('Size of test set: ' + str(len(test_set)) + ' samples')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training set: 60000 samples\n",
            "Size of test set: 10000 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EGtnadiqJ2Nu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setting architecture\n",
        "\n",
        "Creating a common CNN architecture composed of Convolutional and Fully Connected Layers.\n",
        "\n",
        "Links úteis:\n",
        "\n",
        "Função view() que dá reshape no tensor para adequá-lo ao tamanho da entrada das camadas. https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view\n",
        "\n",
        "Pacote torch.nn que contém as implementações das camadas. https://pytorch.org/docs/stable/nn.html"
      ]
    },
    {
      "metadata": {
        "id": "P4oFGFAKJ2Nv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "60fee264-e71a-4d69-d710-349887d0ffd8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532880342180,
          "user_tz": 180,
          "elapsed": 1502,
          "user": {
            "displayName": "Hugo Neves",
            "photoUrl": "//lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s50-c-k-no/photo.jpg",
            "userId": "115244738658251423663"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Customized Network.\n",
        "class CustomNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels, num_classes=10):\n",
        "\n",
        "        super(CustomNetwork, self).__init__()\n",
        "        \n",
        "        # TO DO: Implementar a arquitetura de uma MLP.\n",
        "        # Exemplo de camada: self.layer1 = nn.Linear(args)\n",
        "        ########################################################################\n",
        "        self.n_outputs_1 = 256\n",
        "        self.n_outputs_2 = 128\n",
        "        self.n_outputs_3 = num_classes\n",
        "        \n",
        "        self.layer1 = nn.Linear(in_channels * 28 * 28, self.n_outputs_1) # Fully Connected Layer: 784 -> 256.\n",
        "        self.ativ1 = nn.ReLU(inplace=True)                               # ReLU Activation Layer.\n",
        "        self.drop1 = nn.Dropout()                                        # Dropout Regularization Layer.\n",
        "        \n",
        "        self.layer2 = nn.Linear(self.n_outputs_1, self.n_outputs_2)      # Fully Connected Layer: 256 -> 128.\n",
        "        self.ativ2 = nn.ReLU(inplace=True)                               # ReLU Activation Layer.\n",
        "        self.drop2 = nn.Dropout()                                        # Dropout Regularization Layer.\n",
        "        \n",
        "        self.layer3 = nn.Linear(self.n_outputs_2, self.n_outputs_3)      # Fully Connected Layer: 128 -> 10.\n",
        "        ########################################################################\n",
        "        \n",
        "        self.initialize_weights()\n",
        "    \n",
        "    # Function for randomly initializing weights.\n",
        "    def initialize_weights(self):\n",
        "        \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "                \n",
        "    # Forward function.\n",
        "    def forward(self, x):\n",
        "        \n",
        "        # TO DO: Implementar o forward.\n",
        "        # Deve retornar a saída da última camada da rede.\n",
        "        # A variável 'x' de entrada tem dimensões (BATCH_SIZE, N_CHANNELS, WIDTH, HEIGHT) = (100, 1, 28, 28).\n",
        "        # A saída deve ter dimensões (BATCH_SIZE, N_CLASSES) = (100, 10).\n",
        "        # Exemplo de forward em uma camada: out1 = self.layer1(x)\n",
        "        # Um bom exercício é verificar o tamanho de todas as saídas da rede neural. Para verificar o tamanho de um tensor 'a', usar a função size: print(a.size()).\n",
        "        ########################################################################\n",
        "        \n",
        "        #print('original shape', x.size()) # Comment this line for less text during execution.\n",
        "        x = x.view(x.size(0), -1) # Reshaping tensor from (BATCH_SIZE, CHANNEL_SIZE, HEIGHT, WIDTH) to (BATCH_SIZE, CHANNEL_SIZE * HEIGHT * WIDTH).\n",
        "        #print('transformed shape', x.size()) # Comment this line for less text during execution.\n",
        "        \n",
        "        out1 = self.layer1(x)\n",
        "        out1 = self.ativ1(out1)\n",
        "        out1 = self.drop1(out1)\n",
        "        #print('out1', out1.size()) # Comment this line for less text during execution.\n",
        "        \n",
        "        out2 = self.layer2(out1)\n",
        "        out2 = self.ativ2(out2)\n",
        "        out2 = self.drop2(out2)\n",
        "        #print('out2', out2.size()) # Comment this line for less text during execution.\n",
        "        \n",
        "        out3 = self.layer3(out2)\n",
        "        #print('out3', out3.size()) # Comment this line for less text during execution.\n",
        "        \n",
        "        return out3\n",
        "        ########################################################################\n",
        "        \n",
        "# Instancing Network.\n",
        "in_channels = 1 # The input images only contain 1 channel.\n",
        "num_classes = 10 # MNIST has 10 classes.\n",
        "\n",
        "# model = CustomNetwork(in_channels, num_classes) # CPU version.\n",
        "model = CustomNetwork(in_channels, num_classes).cuda() # GPU casting.\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CustomNetwork(\n",
            "  (layer1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (ativ1): ReLU(inplace)\n",
            "  (drop1): Dropout(p=0.5)\n",
            "  (layer2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (ativ2): ReLU(inplace)\n",
            "  (drop2): Dropout(p=0.5)\n",
            "  (layer3): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VOVXXfCiJ2Ny",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setting optimizer\n",
        "\n",
        "$Pytorch$ has several options for optimizers, since the traditional SGD to more complex per-parameter adaptive ones (i.e. Adam, Adagrad, RSMProp...). All of them are located in the package torch.optim."
      ]
    },
    {
      "metadata": {
        "id": "fhyopppRJ2Nz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.001 # Learning rate.\n",
        "l2_normalization = 0.001 # L2 Normalization via weight decay.\n",
        "\n",
        "opt = optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999), weight_decay=l2_normalization)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MlBTGdzPJ2N1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setting loss criterion\n",
        "\n",
        "$CrossEntropyLoss$, as this is a classification task."
      ]
    },
    {
      "metadata": {
        "id": "H1WirBm_J2N2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Setting a classification loss.\n",
        "# criterion = nn.CrossEntropyLoss() # CPU version.\n",
        "criterion = nn.CrossEntropyLoss().cuda() # GPU casting."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d9uC1yHfJ2N4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training/Testing\n",
        "\n",
        "Iterating over epochs and batches."
      ]
    },
    {
      "metadata": {
        "id": "04-4qarbJ2N5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1883
        },
        "outputId": "6569fd73-361f-4647-e302-472fe1f0f951"
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "epochs = 20 # Run network for 20 epochs.\n",
        "\n",
        "training_metrics = list() # List for accuracies in training procedure.\n",
        "test_metrics = list() # List for accuracies in test procedure.\n",
        "\n",
        "# Iterating over epochs.\n",
        "for ep in range(epochs):\n",
        "    \n",
        "    print('##############################################')\n",
        "    print('Starting epoch ' + str(ep + 1) + '/' + str(epochs) + '...')\n",
        "    \n",
        "    #####################################################################\n",
        "    # Training Procedure. ###############################################\n",
        "    #####################################################################\n",
        "    \n",
        "    print('    Training...')\n",
        "    \n",
        "    # Setting model to training mode.\n",
        "    model.train()\n",
        "    \n",
        "    total_correct = 0\n",
        "    \n",
        "    # Iterating over training batches.\n",
        "    for it, data in enumerate(train_loader):\n",
        "\n",
        "        # Obtaining images and labels for batch.\n",
        "        inps, labs = data\n",
        "        \n",
        "        # GPU casting. In CPU version, remove the following two lines.\n",
        "        inps = Variable(inps.cuda(), requires_grad=True)\n",
        "        labs = Variable(labs.cuda(), requires_grad=False) # requires_grad = False -> it isn't necessary to compute gradients from targets, only from losses.\n",
        "        \n",
        "        # Zeroing optimizer.\n",
        "        opt.zero_grad()\n",
        "        \n",
        "        # Forwarding inputs through DNN.\n",
        "        output = model(inps)\n",
        "        \n",
        "        # Computing loss according to network prediction for batch and targets.\n",
        "        # The Cross Entropy loss receives an output of size (BATCH_SIZE, N_CLASSES) and a label vector of size (BATCH_SIZE).\n",
        "        loss = criterion(output, labs)\n",
        "        \n",
        "        # Backpropagating loss.\n",
        "        loss.backward() # All backward pass is computed from this line automatically by package torch.autograd.\n",
        "        \n",
        "        # Taking optimization step.\n",
        "        opt.step()\n",
        "        \n",
        "        # Computing prediction to batch\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        \n",
        "        # Computing accuracy for batch.\n",
        "        correct = pred.eq(labs.view_as(pred)).sum().item()\n",
        "        accuracy = (100.0 * float(correct) / inps.size(0))\n",
        "        \n",
        "        training_metrics.append(accuracy)\n",
        "        \n",
        "        # Updating total counter.\n",
        "        total_correct += correct\n",
        "        \n",
        "    # Computing accuracy for whole epoch.\n",
        "    accuracy = 100.0 * float(total_correct) / len(train_set)\n",
        "    \n",
        "    print('        Accuracy for training epoch [' + str(ep + 1) + ' / ' + str(epochs) + ']: ' + str(accuracy))\n",
        "    \n",
        "    #####################################################################\n",
        "    # Testing Procedure.  ###############################################\n",
        "    #####################################################################\n",
        "    \n",
        "    print('    Testing...')\n",
        "        \n",
        "    # Setting model to evaluation mode.\n",
        "    model.eval()\n",
        "    \n",
        "    total_correct = 0\n",
        "\n",
        "    # Iterating over test batches.\n",
        "    for it, data in enumerate(test_loader):\n",
        "\n",
        "        # Obtaining images and labels for batch.\n",
        "        inps, labs = data\n",
        "        \n",
        "        # GPU casting. In CPU version, remove the following line.\n",
        "        inps = Variable(inps.cuda(), requires_grad=True)\n",
        "        labs = Variable(labs.cuda(), requires_grad=False)\n",
        "        \n",
        "        # Forwarding through DNN.\n",
        "        output = model(inps)\n",
        "        \n",
        "        # Computing prediction to batch\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        \n",
        "        # Computing accuracy for batch.\n",
        "        correct = pred.eq(labs.view_as(pred)).sum().item()\n",
        "        accuracy = (100.0 * float(correct) / inps.size(0))\n",
        "        \n",
        "        # Appending accuracy in list of accuracies for all batches.\n",
        "        test_metrics.append(accuracy)\n",
        "        \n",
        "        # Updating total counter.\n",
        "        total_correct += correct\n",
        "        \n",
        "    # Computing accuracy for whole epoch.\n",
        "    accuracy = 100.0 * float(total_correct) / len(test_set)\n",
        "    \n",
        "    print('        Accuracy for test epoch [' + str(ep + 1) + ' / ' + str(epochs) + ']: ' + str(accuracy))\n",
        "    \n",
        "# Transforming list into ndarray for plotting.\n",
        "training_array = np.asarray(training_metrics, dtype=np.float32)\n",
        "test_array = np.asarray(test_metrics, dtype=np.float32)\n",
        "\n",
        "# Plotting accuracy.\n",
        "fig, ax = plt.subplots(1, 2, figsize = (16, 8), sharex = False, sharey = True)\n",
        "\n",
        "training_plt = ax[0].plot(training_array)\n",
        "ax[0].set_xlabel('Training')\n",
        "ax[0].set_ylim([0, 100])\n",
        "\n",
        "test_plt = ax[1].plot(test_array)\n",
        "ax[1].set_xlabel('Test')\n",
        "ax[1].set_ylim([0, 100])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##############################################\n",
            "Starting epoch 1/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [1 / 20]: 82.875\n",
            "    Testing...\n",
            "        Accuracy for test epoch [1 / 20]: 92.71\n",
            "##############################################\n",
            "Starting epoch 2/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [2 / 20]: 92.25666666666666\n",
            "    Testing...\n",
            "        Accuracy for test epoch [2 / 20]: 95.42\n",
            "##############################################\n",
            "Starting epoch 3/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [3 / 20]: 93.635\n",
            "    Testing...\n",
            "        Accuracy for test epoch [3 / 20]: 95.76\n",
            "##############################################\n",
            "Starting epoch 4/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [4 / 20]: 94.325\n",
            "    Testing...\n",
            "        Accuracy for test epoch [4 / 20]: 96.54\n",
            "##############################################\n",
            "Starting epoch 5/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [5 / 20]: 94.74166666666666\n",
            "    Testing...\n",
            "        Accuracy for test epoch [5 / 20]: 96.8\n",
            "##############################################\n",
            "Starting epoch 6/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [6 / 20]: 94.90833333333333\n",
            "    Testing...\n",
            "        Accuracy for test epoch [6 / 20]: 96.98\n",
            "##############################################\n",
            "Starting epoch 7/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [7 / 20]: 95.12833333333333\n",
            "    Testing...\n",
            "        Accuracy for test epoch [7 / 20]: 97.08\n",
            "##############################################\n",
            "Starting epoch 8/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [8 / 20]: 95.37833333333333\n",
            "    Testing...\n",
            "        Accuracy for test epoch [8 / 20]: 97.28\n",
            "##############################################\n",
            "Starting epoch 9/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [9 / 20]: 95.43333333333334\n",
            "    Testing...\n",
            "        Accuracy for test epoch [9 / 20]: 97.07\n",
            "##############################################\n",
            "Starting epoch 10/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [10 / 20]: 95.44166666666666\n",
            "    Testing...\n",
            "        Accuracy for test epoch [10 / 20]: 97.18\n",
            "##############################################\n",
            "Starting epoch 11/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [11 / 20]: 95.53833333333333\n",
            "    Testing...\n",
            "        Accuracy for test epoch [11 / 20]: 96.87\n",
            "##############################################\n",
            "Starting epoch 12/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [12 / 20]: 95.51833333333333\n",
            "    Testing...\n",
            "        Accuracy for test epoch [12 / 20]: 97.42\n",
            "##############################################\n",
            "Starting epoch 13/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [13 / 20]: 95.57333333333334\n",
            "    Testing...\n",
            "        Accuracy for test epoch [13 / 20]: 97.59\n",
            "##############################################\n",
            "Starting epoch 14/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [14 / 20]: 95.66166666666666\n",
            "    Testing...\n",
            "        Accuracy for test epoch [14 / 20]: 97.36\n",
            "##############################################\n",
            "Starting epoch 15/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [15 / 20]: 95.65166666666667\n",
            "    Testing...\n",
            "        Accuracy for test epoch [15 / 20]: 97.46\n",
            "##############################################\n",
            "Starting epoch 16/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [16 / 20]: 95.725\n",
            "    Testing...\n",
            "        Accuracy for test epoch [16 / 20]: 97.37\n",
            "##############################################\n",
            "Starting epoch 17/20...\n",
            "    Training...\n",
            "        Accuracy for training epoch [17 / 20]: 95.80666666666667\n",
            "    Testing...\n",
            "        Accuracy for test epoch [17 / 20]: 97.44\n",
            "##############################################\n",
            "Starting epoch 18/20...\n",
            "    Training...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}