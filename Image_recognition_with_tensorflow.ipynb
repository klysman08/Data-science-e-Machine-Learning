{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image-recognition-with-tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kK_7OJtuP_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importando os modulos\n",
        "\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.constraints import maxnorm\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT4RQQFducvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 21"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMsUu2P-urvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#O CIFAR-10 é um conjunto de dados de imagens grandes contendo mais de 60.000 imagens representando 10 classes diferentes de objetos, como gatos, aviões e carros.\n",
        "\n",
        "from keras.datasets import cifar10 # importando os dados CIFAR10 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1wiooaxuvM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Carregando os conjutos de dados do dataset CIFAR10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuJYvZRBvMDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Transformando os dados em um tipo flutuando. As imagens estão com valores de 255. Devemos dividir por esse valor para normalizalos \n",
        "#Assim não estaremos sobracarregando a rede de aprendizado \n",
        "\n",
        "# normalize the inputs from 0-255 to between 0 and 1 by dividing by 255\n",
        "    \n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg12oNwQvzL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#As imagens precisam ser codificadas primeiro\n",
        "#Usaremos a codificação binaria para esse caso\n",
        "# one hot encode outputs\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "class_num = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alFBueNoxleR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKnzPu04x23n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Criando o modelo de aprendizado do Keras\n",
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UeEbAqi1cyb",
        "colab_type": "text"
      },
      "source": [
        "Ao implementar estes em Keras, temos que especificar o número de canais \n",
        "O filtros que queremos (que é o 32 abaixo pois as imagens são deste tamanho)\n",
        "o tamanho do filtro que queremos (3 x 3, neste caso), a forma de entrada (ao criar a primeira camada ) e a ativação e preenchimento que precisamos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iou1hFO2yWJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A primeira camada do nosso modelo é uma camada convolucional. \n",
        "#Ele irá receber as entradas e executar filtros convolucionais nelas.\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:], padding='same')) #padding='same'significa apenas que não estamos alterando o tamanho da imagem:\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYxeFxm_2LwG",
        "colab_type": "text"
      },
      "source": [
        "Agora faremos uma camada de dropout para evitar overfitting, que funciona eliminando aleatoriamente algumas das conexões entre as camadas (0.2 significa que cai 20% das conexões existentes):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeWFek9K1t6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbkqP3w04mIJ",
        "colab_type": "text"
      },
      "source": [
        "Também podemos querer fazer a normalização em lote aqui. A normalização em lote normaliza as entradas indo para a próxima camada, garantindo que a rede sempre crie ativações com a mesma distribuição que desejamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghFelVKj2QB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd48m-MA46SB",
        "colab_type": "text"
      },
      "source": [
        "Agora vem outra camada convolucional, mas o tamanho do filtro aumenta para que a rede possa aprender representações mais complexas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saJQ6-2n4tdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgzc2bP75GPU",
        "colab_type": "text"
      },
      "source": [
        "Aqui está a camada de pooling, como discutido antes, isso ajuda a tornar o classificador de imagem mais robusto, para que ele possa aprender padrões relevantes. Há também a eliminação e a normalização do lote:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLXIaCze49q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjsfTbuK5Rkc",
        "colab_type": "text"
      },
      "source": [
        "Esse é o fluxo básico para a primeira metade de uma implementação da CNN: Convolutional, ativação, dropout, pooling .\n",
        "\n",
        "É importante não ter muitas camadas de pooling, pois cada pool descarta alguns dados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuUV11Zs5I7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Quanto mais camadas na rede mais representações para trabalhar\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQo8whqb6EMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOFiLgk76HE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZy8u_Fz6vtu",
        "colab_type": "text"
      },
      "source": [
        "Agora fazemos uso da Denseimportação e criamos a primeira camada densamente conectada. Precisamos especificar o número de neurônios na camada densa. Observe que o número de neurônios nas camadas seguintes diminui, aproximando-se do mesmo número de neurônios que existem no conjunto de dados (neste caso, 10). A restrição do kernel pode regularizar os dados à medida que aprende, outra coisa que ajuda a evitar o overfitting. É por isso que nós importamos maxnormmais cedo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u681ZzXl6gHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(256, kernel_constraint=maxnorm(3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovZVJYQS6yXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(128, kernel_constraint=maxnorm(3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hukvf4m27B-e",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, a softmaxfunção de ativação seleciona o neurônio com a maior probabilidade como saída, votando que a imagem pertence a essa classe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEwKd4mi7Eo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(class_num))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9VtQn5x7OZ7",
        "colab_type": "text"
      },
      "source": [
        "O otimizador é o que ajustará os pesos em sua rede para se aproximar do ponto de menor perda. O Adamalgoritmo é um dos otimizadores mais comumente usados, pois oferece ótimo desempenho na maioria dos problemas.\n",
        "\n",
        "Necessitamos escolher um numero de épocas (tempo) de treino para nossa rede. Se escolhermos um numero muito baixo de épocas, nosso algoritmo não convirjará para um mínimo global. Se escolhermos um numero muito grande, correremos o risco de nosso algoritmo se acostumar demais aos dados de teste, e terá má performance em dados reais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Yq496i7FKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 25\n",
        "optimizer = 'adam'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D02IVtOn8AQf",
        "colab_type": "text"
      },
      "source": [
        "Vamos agora compilar o modelo com nossos parâmetros escolhidos. Vamos também especificar uma métrica para usar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpLAUROI761S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOHuBKJH8CI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "736e97d2-60c1-4b93-8a4c-accb21477c3e"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,264,458\n",
            "Trainable params: 2,263,114\n",
            "Non-trainable params: 1,344\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgt-QQH48VSr",
        "colab_type": "text"
      },
      "source": [
        "Agora nós começamos a treinar o modelo. Para fazer isso, tudo o que precisamos fazer é chamar a fit()função no modelo e passar os parâmetros escolhidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6lX-Xeg8GJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "ffb3a50d-b072-4ad3-cc1a-7d243a4cbdcd"
      },
      "source": [
        "numpy.random.seed(seed)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0731 21:31:09.335075 139872616568704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "50000/50000 [==============================] - 19s 388us/step - loss: 1.5100 - acc: 0.4606 - val_loss: 1.2841 - val_acc: 0.5304\n",
            "Epoch 2/25\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 1.0490 - acc: 0.6308 - val_loss: 0.8584 - val_acc: 0.6918\n",
            "Epoch 3/25\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.8576 - acc: 0.7003 - val_loss: 0.7947 - val_acc: 0.7208\n",
            "Epoch 4/25\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.7540 - acc: 0.7358 - val_loss: 0.6775 - val_acc: 0.7639\n",
            "Epoch 5/25\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.7002 - acc: 0.7540 - val_loss: 0.6500 - val_acc: 0.7696\n",
            "Epoch 6/25\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.6566 - acc: 0.7704 - val_loss: 0.6230 - val_acc: 0.7840\n",
            "Epoch 7/25\n",
            "50000/50000 [==============================] - 14s 287us/step - loss: 0.6233 - acc: 0.7815 - val_loss: 0.6766 - val_acc: 0.7633\n",
            "Epoch 8/25\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.5966 - acc: 0.7902 - val_loss: 0.5962 - val_acc: 0.7965\n",
            "Epoch 9/25\n",
            "50000/50000 [==============================] - 14s 284us/step - loss: 0.5684 - acc: 0.8024 - val_loss: 0.6079 - val_acc: 0.7909\n",
            "Epoch 10/25\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.5551 - acc: 0.8078 - val_loss: 0.6841 - val_acc: 0.7717\n",
            "Epoch 11/25\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.5343 - acc: 0.8117 - val_loss: 0.5642 - val_acc: 0.8068\n",
            "Epoch 12/25\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.5160 - acc: 0.8189 - val_loss: 0.6503 - val_acc: 0.7727\n",
            "Epoch 13/25\n",
            "50000/50000 [==============================] - 14s 287us/step - loss: 0.5053 - acc: 0.8231 - val_loss: 0.5379 - val_acc: 0.8140\n",
            "Epoch 14/25\n",
            "50000/50000 [==============================] - 14s 288us/step - loss: 0.4923 - acc: 0.8274 - val_loss: 0.5937 - val_acc: 0.7975\n",
            "Epoch 15/25\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.4757 - acc: 0.8339 - val_loss: 0.5303 - val_acc: 0.8207\n",
            "Epoch 16/25\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.4702 - acc: 0.8360 - val_loss: 0.5437 - val_acc: 0.8134\n",
            "Epoch 17/25\n",
            "50000/50000 [==============================] - 14s 287us/step - loss: 0.4597 - acc: 0.8409 - val_loss: 0.5577 - val_acc: 0.8087\n",
            "Epoch 18/25\n",
            "50000/50000 [==============================] - 14s 287us/step - loss: 0.4519 - acc: 0.8427 - val_loss: 0.5485 - val_acc: 0.8120\n",
            "Epoch 19/25\n",
            "50000/50000 [==============================] - 14s 289us/step - loss: 0.4433 - acc: 0.8452 - val_loss: 0.5070 - val_acc: 0.8292\n",
            "Epoch 20/25\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.4436 - acc: 0.8458 - val_loss: 0.5562 - val_acc: 0.8114\n",
            "Epoch 21/25\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.4349 - acc: 0.8491 - val_loss: 0.5431 - val_acc: 0.8154\n",
            "Epoch 22/25\n",
            "50000/50000 [==============================] - 14s 286us/step - loss: 0.4343 - acc: 0.8493 - val_loss: 0.5269 - val_acc: 0.8201\n",
            "Epoch 23/25\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.4169 - acc: 0.8543 - val_loss: 0.4836 - val_acc: 0.8347\n",
            "Epoch 24/25\n",
            "50000/50000 [==============================] - 14s 288us/step - loss: 0.4143 - acc: 0.8554 - val_loss: 0.5354 - val_acc: 0.8241\n",
            "Epoch 25/25\n",
            "50000/50000 [==============================] - 14s 285us/step - loss: 0.4112 - acc: 0.8556 - val_loss: 0.5005 - val_acc: 0.8314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36404264a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqCUdfwA-W5q",
        "colab_type": "text"
      },
      "source": [
        "Agora podemos avaliar o modelo e ver como ele é executado. Basta usar model.evaluate():"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bDs5xUC8aQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ea583103-3dd6-4f1d-98f8-849fb9a8a98c"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 83.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18R2PuJP-9th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}