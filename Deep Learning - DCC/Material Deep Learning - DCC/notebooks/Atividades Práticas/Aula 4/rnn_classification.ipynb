{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "BN_P5qE9DD7f",
        "T58yGDm8FlSd",
        "AMJDZoNrW1wN",
        "j5Pr5dvWh_Jb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "xWbKs2L2VLAN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classificando nomes com uma *Character-Level RNN*"
      ]
    },
    {
      "metadata": {
        "id": "JzlUoQmIVPod",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "u3yTcZViBgS8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Problema: Dado um nome próprio de entrada, classificar esse nome de acordo com a nacionalidade a que ele pertence."
      ]
    },
    {
      "metadata": {
        "id": "ehwomfzYVZNe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "python predict.py **Hinton**\n",
        "\n",
        "(-0.47) Scottish\n",
        "\n",
        "(-1.52) English\n",
        "\n",
        "(-3.57) Irish\n",
        "\n",
        "\n",
        "-\n",
        "\n",
        "python predict.py **Schmidhuber**\n",
        "\n",
        "(-0.19) German\n",
        "\n",
        "(-2.48) Czech\n",
        "\n",
        "(-2.68) Dutch"
      ]
    },
    {
      "metadata": {
        "id": "-r2eSYyYB78h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "### Import de bibliotecas"
      ]
    },
    {
      "metadata": {
        "id": "PIPESSWBeXKC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "  \n",
        "import unicodedata\n",
        "import torch\n",
        "import string\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import sys, random, os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "skDOjmZZCCzc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### Importando dataset"
      ]
    },
    {
      "metadata": {
        "id": "T09ezsbbVETm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# comente as duas linhas seguintes caso rode mais de uma vez\n",
        "!wget https://download.pytorch.org/tutorial/data.zip #\n",
        "!unzip data.zip #\n",
        "############################################################\n",
        "\n",
        "root_path = 'data/names/'\n",
        "all_filenames = []\n",
        "for file_name in os.listdir(root_path):\n",
        "  all_filenames.append(os.path.join(root_path,file_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ltk3-NJabrHz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "# Read a file and split into lines\n",
        "def readLines(filename):\n",
        "    lines = open(filename).read().strip().split('\\n')\n",
        "    #return lines\n",
        "    return [unicodedata.normalize('NFKD', line).encode('ascii', 'ignore') for line in lines]\n",
        "\n",
        "for filename in all_filenames:\n",
        "    category = filename.split('/')[-1].split('.')[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename)\n",
        "    category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)\n",
        "print('n_categories =', n_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mi6dNGFLdNU6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "category_lines['Italian'][:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BN_P5qE9DD7f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "### Convertendo caracteres para tensores\n",
        "Nesse caso, cada caracter será convertido para uma representação *one-hot*\n"
      ]
    },
    {
      "metadata": {
        "id": "AxEA1ClZds4c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "def letter_to_tensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    letter_index = all_letters.find(letter)\n",
        "    tensor[0][letter_index] = 1\n",
        "    return tensor\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>,\n",
        "# or an array of one-hot letter vectors\n",
        "def line_to_tensor(line):\n",
        "    tensor = torch.zeros(len(line), n_letters)\n",
        "    for li, letter in enumerate(line.decode('utf-8')):\n",
        "        letter_index = all_letters.find(letter)\n",
        "        tensor[li][letter_index] = 1\n",
        "    return tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Sv4Giioe8RS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(letter_to_tensor('a'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T58yGDm8FlSd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Funções auxiliares para estruturar as amostras de treino e teste"
      ]
    },
    {
      "metadata": {
        "id": "Od2ko1iD6krC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def category_from_output(output):\n",
        "    top_n, top_i = output.data.topk(1) # Tensor out of Variable with .data\n",
        "    category_i = top_i[0][0]\n",
        "    return all_categories[category_i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x3B_1fpTF9P-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split as split\n",
        "\n",
        "X_train, X_test = {}, {}\n",
        "for category in all_categories:\n",
        "  train, test = split(category_lines[category], test_size=0.1)\n",
        "  \n",
        "  X_train[category] = train\n",
        "  X_test[category] = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4k4IaUFvDt0v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Construindo modelo RNN\n",
        "\n",
        "* Implemente um modelo para classificação de nomes próprios (série de caracteres) usando apenas camadas *RNNCell*, *Linear* e ativação *LogSoftmax*\n",
        "* Cada entrada (caracter) possui dimensão (57): alfabeto maiúsculo e minúsculo\n",
        "* *Hidden size* possui dimensão (256): hiperparâmetro \n",
        "* Saída possui dimensão (18): vetor de probabilidade de classes\n",
        "* Batch size = 1 de acordo com a implementação do loop de treinamento\n",
        "\n",
        "**Links úteis**\n",
        "\n",
        "RNNCell: https://pytorch.org/docs/stable/nn.html#torch.nn.RNNCell\n",
        "\n",
        "Linear: https://pytorch.org/docs/stable/nn.html#torch.nn.Linear\n",
        "\n",
        "Non-linear activations: https://pytorch.org/docs/stable/nn.html#non-linear-activations-other\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "BtIFLlfKfIBH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, nonlinearity='tanh'):\n",
        "        super(CustomNetwork, self).__init__()\n",
        "        \n",
        "\n",
        "    \n",
        "    def forward(self, input):\n",
        "      \n",
        "      # Set initial hidden state \n",
        "      #self.hidden = Variable( ).double()\n",
        "      self.hidden = Variable( ''' Adicione aqui a inicialização do hidden state ''' ).double().cuda() #GPU\n",
        "        \n",
        "\n",
        "n_hidden = 256\n",
        "model = CustomNetwork(n_letters, n_hidden, n_categories)\n",
        "model.double().cuda() #GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgppRhH7ZRIY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Instanciando *Loss* e Otimizador"
      ]
    },
    {
      "metadata": {
        "id": "4HGEyjwRZXjV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss().cuda() #GPU\n",
        "learning_rate  = 0.0002 \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hpRfr8HrFtF4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Treinando / Testando modelo"
      ]
    },
    {
      "metadata": {
        "id": "vzY7EaLWQpe3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "num_steps  = 2000\n",
        "print_every = 2000\n",
        "\n",
        "current_loss = 0\n",
        "current_acc = 0\n",
        "all_losses, all_val_losses, all_acc, all_val_acc = [], [], [], []\n",
        "for epoch in range(num_epochs):  \n",
        "\n",
        "  for step in range(num_steps):\n",
        "    \n",
        "    # Set to Train Mode\n",
        "    model.train()\n",
        "    \n",
        "    category = random.choice(all_categories)\n",
        "    line = random.choice(X_train[category])\n",
        "  \n",
        "    #category_tensor = Variable(torch.LongTensor([all_categories.index(category)]))\n",
        "    #line_tensor     = Variable(line_to_tensor(line))\n",
        "    category_tensor = Variable(torch.LongTensor([all_categories.index(category)])).cuda() #GPU\n",
        "    line_tensor     = Variable(line_to_tensor(line)).double().cuda() #GPU\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(line_tensor)\n",
        "    loss = criterion(output, category_tensor)\n",
        "    current_loss += loss\n",
        "    current_acc  += 1 if category_from_output(output) == category else 0\n",
        "    \n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (step+1) % print_every == 0:\n",
        "      \n",
        "      #Set to evaluation mode\n",
        "      model.eval()\n",
        "      n_test_steps = 100\n",
        "      \n",
        "      test_loss, acc = 0, 0\n",
        "      for tstep in range(n_test_steps):\n",
        "      \n",
        "        category = random.choice(all_categories)\n",
        "        line = random.choice(X_test[category])\n",
        "\n",
        "        #category_tensor = Variable(torch.LongTensor([all_categories.index(category)]))\n",
        "        #line_tensor     = Variable(line_to_tensor(line))\n",
        "        category_tensor = Variable(torch.LongTensor([all_categories.index(category)])).cuda() #GPU\n",
        "        line_tensor     = Variable(line_to_tensor(line)).double().cuda() #GPU\n",
        "\n",
        "        output = model(line_tensor)\n",
        "        loss = criterion(output, category_tensor)\n",
        "        test_loss += loss\n",
        "        acc += 1 if category_from_output(output) == category else 0\n",
        "      \n",
        "      \n",
        "      current_loss = current_loss.data[0]/float(print_every)\n",
        "      current_acc  = current_acc/float(print_every)\n",
        "      test_loss    = test_loss.data[0]/float(n_test_steps)\n",
        "      acc          = acc/float(n_test_steps)\n",
        "      \n",
        "      print('\\rEpoch: {0} Train Loss: {2} Train Acc: {3}% Val Loss: {4}  Val Acc: {5}%'.format(epoch+1, step, current_loss, current_acc*100, test_loss, acc*100))\n",
        "\n",
        "      all_losses.append(current_loss)\n",
        "      all_acc.append(current_acc)\n",
        "      all_val_losses.append(test_loss)\n",
        "      all_val_acc.append(acc)\n",
        "\n",
        "      current_loss = 0\n",
        "      current_acc  = 0\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AMJDZoNrW1wN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Análise e plots"
      ]
    },
    {
      "metadata": {
        "id": "V75MN9lf9KRK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,3))\n",
        "\n",
        "\n",
        "ax1.plot(all_losses[1:], label='Train')\n",
        "ax1.plot(all_val_losses[1:], label='Test')\n",
        "ax1.set_title('Model Convergence - Loss')\n",
        "ax1.set_xlabel('epochs')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(all_acc, label='Train')\n",
        "ax2.plot(all_val_acc, label='Test')\n",
        "ax2.set_title('Model Convergence - Accuracy')\n",
        "ax2.set_xlabel('epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5Pr5dvWh_Jb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Fazendo predições com entradas de usuário"
      ]
    },
    {
      "metadata": {
        "id": "_MolDbbq9L8p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_input(input_line, n_predictions=3):\n",
        "    print('\\n> %s' % input_line)\n",
        "    \n",
        "    tensor = torch.zeros(len(input_line), n_letters)\n",
        "    for li, letter in enumerate(input_line):\n",
        "        letter_index = all_letters.find(letter)\n",
        "        tensor[li][letter_index] = 1\n",
        "        \n",
        "    output = model(Variable(tensor).double().cuda())\n",
        "\n",
        "    # Get top N categories\n",
        "    topv, topi = output.data.topk(n_predictions, 1, True)\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(n_predictions):\n",
        "        value = topv[0][i]\n",
        "        category_index = topi[0][i]\n",
        "        print('(%.2f) %s' % (value, all_categories[category_index]))\n",
        "        predictions.append([value, all_categories[category_index]])\n",
        "\n",
        "predict_input('Mbappe')\n",
        "predict_input('Guillermo')\n",
        "predict_input('Kyle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tKdXTtU5QUG7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}