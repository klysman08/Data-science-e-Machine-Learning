{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "t27v5B2sc4nR",
        "tXrNIc0mc6o8",
        "OuXki9brc-68"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "zFyPPv2Vg8w-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generate Music Lyrics\n",
        "\n",
        "Dataset: https://www.kaggle.com/mousehead/songlyrics"
      ]
    },
    {
      "metadata": {
        "id": "t27v5B2sc4nR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import libs"
      ]
    },
    {
      "metadata": {
        "id": "r7rW3BDHjiD5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "!pip install unidecode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tXrNIc0mc6o8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get dataset"
      ]
    },
    {
      "metadata": {
        "id": "GI6rtlDXldHU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# comente linhas seguinte caso rode mais de uma vez\n",
        "!wget https://www.dropbox.com/s/gspbmxiabhwrce3/english_lyrics.txt?dl=0\n",
        "############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ybyAg6ayZ5e-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "chunk_len = 200\n",
        "\n",
        "file = open('english_lyrics.txt?dl=0').read()\n",
        "file_len = len(file)\n",
        "\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)\n",
        "  \n",
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "  \n",
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OuXki9brc-68",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set architecture\n",
        "\n",
        "Camadas:\n",
        "* Embedding: https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding\n",
        "* GRU: https://pytorch.org/docs/stable/nn.html#torch.nn.GRU\n",
        "* Linear: https://pytorch.org/docs/stable/nn.html#torch.nn.Linear\n",
        "\n",
        "Auxiliares:\n",
        "View: https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view"
      ]
    },
    {
      "metadata": {
        "id": "OAahmPucVjKW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "    \n",
        "    def forward(self, input, hidden, predict=0):\n",
        "        \n",
        "        \n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size)).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4B4i5cZmdCLw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train / evaluate model"
      ]
    },
    {
      "metadata": {
        "id": "3aHSZqLJp3LL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "    hidden = decoder.init_hidden()\n",
        "    prime_input = char_tensor(prime_str)\n",
        "    predicted = prime_str\n",
        "\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "\n",
        "    _, hidden = decoder(prime_input.cuda(), hidden)\n",
        "    inp = prime_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden = decoder(inp.cuda(), hidden)\n",
        "        \n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = char_tensor(predicted_char)\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O1sEDBJrp8YJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(inp, target):\n",
        "    hidden = decoder.init_hidden()\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    output, hidden = decoder(inp.cuda(), hidden)\n",
        "    loss += criterion(output, target.cuda())\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.data[0] / chunk_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrWO83mUp-E9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_steps = 2000\n",
        "print_every = 100\n",
        "plot_every = 100\n",
        "\n",
        "embedding_size = 128\n",
        "hidden_size = 128\n",
        "n_layers = 2\n",
        "lr = 0.005\n",
        "\n",
        "print('Start')\n",
        "decoder = RNN(n_characters, embedding_size, hidden_size, n_characters, n_layers)\n",
        "decoder.cuda()\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "print('Before Training...')\n",
        "print(evaluate('I', 100), '\\n')\n",
        "\n",
        "for step in range(1, n_steps + 1):\n",
        "    decoder.train()\n",
        "    loss = train(*random_training_set())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if step % print_every == 0:\n",
        "        decoder.eval()\n",
        "        print('[(%d %d%%) %.4f]' % (step, step / n_steps * 100, loss))\n",
        "        print(evaluate('I', 100), '\\n')\n",
        "\n",
        "    if step % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SQU8BhvpqHG8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}