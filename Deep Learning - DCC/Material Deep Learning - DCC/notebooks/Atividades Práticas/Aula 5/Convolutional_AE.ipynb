{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional_AE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Bu6ImUZLGAcM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# Installing pillow v4.0.\n",
        "from PIL import Image\n",
        "!pip install Pillow==4.0.0\n",
        "!pip install image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fcU-gYDgGwfQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.datasets import MNIST\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "###########################################################################################\n",
        "# Adapted from: https://github.com/L1aoXingyu/pytorch-beginner/tree/master/08-AutoEncoder #\n",
        "###########################################################################################\n",
        "\n",
        "if not os.path.exists('./dc_img'):\n",
        "    os.mkdir('./dc_img')\n",
        "\n",
        "def to_img(x):\n",
        "    x = 0.5 * (x + 1)\n",
        "    x = x.clamp(0, 1)\n",
        "    x = x.view(x.size(0), 1, 28, 28)\n",
        "    return x\n",
        "\n",
        "# Parameters.\n",
        "num_epochs = 100\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Defining normalization routine to images.\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Instancing Dataloader and Dataset.\n",
        "dataset = MNIST('./data', transform=img_transform, download=True)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Defining model.\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        # TO DO: Implementar a arquitetura de um AE. Usar o nn.Sequential() para definir os modelos.\n",
        "        # Link úteis: https://pytorch.org/docs/stable/nn.html#torch.nn.ConvTranspose2d\n",
        "        #             https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU\n",
        "        #             https://pytorch.org/docs/stable/nn.html#torch.nn.Tanh\n",
        "        #             https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d\n",
        "        #             https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d\n",
        "        #             https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential\n",
        "        self.encoder = nn.Sequential(\n",
        "            \n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TO DO: Implementar o forward.\n",
        "        # DICA: Não se esqueçam de retornar o resultado.\n",
        "\n",
        "# Instancing Model\n",
        "model = autoencoder().cuda()\n",
        "\n",
        "# Defining Criterion\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Defining Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "# Iterating over epochs.\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Iterating over batches.\n",
        "    for it, data in enumerate(dataloader):\n",
        "\n",
        "        # Reading data and casting to GPU.\n",
        "        img, _ = data\n",
        "        img = Variable(img).cuda()\n",
        "        \n",
        "        # Forward.\n",
        "        output = model(img)\n",
        "        loss = criterion(output, img)\n",
        "        \n",
        "        # Backward.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        # Plotting first batch of each epoch.\n",
        "        if it == 0:\n",
        "            \n",
        "            fig, ax = plt.subplots(8, 8, figsize=(12, 12))\n",
        "            for i in range(8):\n",
        "                for j in range(8):\n",
        "                    ax[i, j].imshow(output.cpu()[i + 4 * j].detach().numpy()[0])\n",
        "                    ax[i, j].set_yticks([])\n",
        "                    ax[i, j].set_xticks([])\n",
        "            plt.show()\n",
        "            \n",
        "    # Printing log.\n",
        "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.data[0]))\n",
        "\n",
        "# Saving model to disk.\n",
        "torch.save(model.state_dict(), './conv_autoencoder.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}